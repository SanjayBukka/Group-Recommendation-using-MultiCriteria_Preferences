{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtn8zezWUOOv",
        "outputId": "915785a0-435d-4a1b-d8d0-b6ccbb3d6d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit-fuzzy-0.4.2.tar.gz (993 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/994.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/994.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/994.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m993.3/994.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.0/994.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.11.4)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (3.3)\n",
            "Building wheels for collected packages: scikit-fuzzy\n",
            "  Building wheel for scikit-fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-fuzzy: filename=scikit_fuzzy-0.4.2-py3-none-any.whl size=894078 sha256=9cab86c50b0ec6195f16840a84b72dbd7ebae057e45f4d9cac67f6a15f7ede86\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/86/1b/dfd97134a2c8313e519bcebd95d3fedc7be7944db022094bc8\n",
            "Successfully built scikit-fuzzy\n",
            "Installing collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGpvR2Yqhn6l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "from scipy.stats import pearsonr\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjaE2wt1hpCq"
      },
      "outputs": [],
      "source": [
        "def read_dataset(dataset_path):\n",
        "    return pd.read_csv(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksK1-OlchpMu"
      },
      "outputs": [],
      "source": [
        "def calculate_preference(user_id, data):\n",
        "    user_data = data[data['User.ID'] == user_id]\n",
        "    if user_data.empty:\n",
        "        return None  # Return None if user ID not found in the dataset\n",
        "\n",
        "    # Columns containing ratings\n",
        "    rating_columns = ['Value.Rating', 'Rooms.Rating', 'Location.Rating', 'Cleanliness.Rating',\n",
        "                      'Front.Desk.Rating', 'Service.Rating', 'Business.Service.Rating']\n",
        "\n",
        "    # Average ratings\n",
        "    average_ratings = data[rating_columns].mean()\n",
        "\n",
        "    # User's ratings\n",
        "    user_ratings = user_data[rating_columns].iloc[0]\n",
        "\n",
        "    # Calculate preferences\n",
        "    preferences = average_ratings - user_ratings\n",
        "\n",
        "    return preferences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VGZmDL4hpN_"
      },
      "outputs": [],
      "source": [
        "def normalize_preferences(preferences):\n",
        "    # Normalize the preferences using Min-Max scaling\n",
        "    min_pref = np.min(preferences)\n",
        "    max_pref = np.max(preferences)\n",
        "    return (preferences - min_pref) / (max_pref - min_pref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ0KOYsXhpTC"
      },
      "outputs": [],
      "source": [
        "def perform_fuzzy_cmeans_clustering(normalized_preferences, c, m, max_iter):\n",
        "    # FCM clustering\n",
        "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
        "        data=normalized_preferences.T, c=c, m=m, error=0.01, maxiter=max_iter, init=None\n",
        "    )\n",
        "\n",
        "    # Assign cluster labels to users\n",
        "    cluster_membership = np.argmax(u, axis=0)\n",
        "    return cluster_membership"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTJ9tYnQhpUa"
      },
      "outputs": [],
      "source": [
        "def filter_users_by_cluster(preferences, cluster_membership, target_cluster):\n",
        "    # Combine the user-item matrix with cluster labels\n",
        "    cluster_labaled_preferences = pd.concat([preferences, pd.DataFrame(cluster_membership, index=preferences.index, columns=[\"Cluster Label\"])], axis=1)\n",
        "\n",
        "    # Filter users from the target cluster\n",
        "    cluster_data = cluster_labaled_preferences[cluster_labaled_preferences[\"Cluster Label\"] == target_cluster]\n",
        "\n",
        "    # Delete the \"Cluster Label\" column\n",
        "    del cluster_data[\"Cluster Label\"]\n",
        "\n",
        "    return cluster_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-yAIL6NhpZB"
      },
      "outputs": [],
      "source": [
        "def calculate_pcc(user1_preferences, user2_preferences):\n",
        "    # Convert to numpy arrays\n",
        "    x = np.array(user1_preferences)\n",
        "    y = np.array(user2_preferences)\n",
        "\n",
        "    # Calculate Pearson correlation coefficient\n",
        "    return pearsonr(x, y)[0] if len(x) == len(y) else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ciNOIvMhpah"
      },
      "outputs": [],
      "source": [
        "    # Calculate PCC with the randomly selected user for all users in the same cluster\n",
        "    pcc_values = []\n",
        "\n",
        "    for user_id in cluster_data.index.unique():\n",
        "        if user_id != random_user:\n",
        "            user1_preferences = cluster_data.loc[random_user]\n",
        "            user2_preferences = cluster_data.loc[user_id]\n",
        "\n",
        "            pcc = calculate_pcc(user1_preferences, user2_preferences)\n",
        "            if pcc is not None:\n",
        "                pcc_values.append((user_id, pcc))\n",
        "\n",
        "    # Sort users by PCC values in descending order\n",
        "    pcc_values.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Extract the user IDs of the top similar users\n",
        "    similar_user_ids = [user_id for user_id, _ in pcc_values][:group_size]\n",
        "\n",
        "    # Create a new DataFrame containing data of the top similar users as a group\n",
        "    group_data = cluster_data.loc[similar_user_ids]\n",
        "\n",
        "    return group_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dM__Y5thpgL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial import distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7O0zO0phpjM"
      },
      "outputs": [],
      "source": [
        "def calculate_trust(Group):\n",
        "    members = Group.index\n",
        "    no_member = len(members)\n",
        "\n",
        "    Trust_matrix = pd.DataFrame(0.0, index=members, columns=members)\n",
        "\n",
        "    for u in members:\n",
        "        rated_list_u = Group.loc[u].index[Group.loc[u] > 0]\n",
        "        count_rated_u = len(rated_list_u)\n",
        "        ratings_u = Group.loc[u][:]\n",
        "\n",
        "        if count_rated_u == 0:\n",
        "            continue  # Skip if there are no rated items for user u\n",
        "\n",
        "        for v in members:\n",
        "            if u == v:\n",
        "                continue\n",
        "\n",
        "            rated_list_v = Group.loc[v].index[Group.loc[v] > 0]\n",
        "            count_rated_v = len(rated_list_v)\n",
        "            ratings_v = Group.loc[v][:]\n",
        "\n",
        "            intersection_uv = set(rated_list_u).intersection(rated_list_v)\n",
        "            count_intersection = len(intersection_uv)\n",
        "\n",
        "            partnership_uv = count_intersection / count_rated_u\n",
        "\n",
        "            dst_uv = 1 / (1 + distance.euclidean(ratings_u, ratings_v))\n",
        "\n",
        "            trust_uv = (2 * partnership_uv * dst_uv) / (partnership_uv + dst_uv)\n",
        "            Trust_matrix.at[u, v] = trust_uv\n",
        "\n",
        "    return Trust_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgDGdKvGhplA"
      },
      "outputs": [],
      "source": [
        "def calculate_similarity(Group):\n",
        "    members = Group.index\n",
        "    ratings = Group.to_numpy()  # Convert DataFrame to a NumPy array\n",
        "\n",
        "    # Calculate the Pearson correlation coefficient similarity\n",
        "    PCC = np.corrcoef(ratings, rowvar=True)\n",
        "\n",
        "    # Convert the matrix to a DataFrame with proper index and columns\n",
        "    PCC_df = pd.DataFrame(PCC, index=members, columns=members)\n",
        "\n",
        "    return PCC_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdIuGqtihpov"
      },
      "outputs": [],
      "source": [
        "# Function to identify leader within a group based on Trust and Similarity matrices\n",
        "def identify_leader(Trust_matrix, Similarity_matrix, total_members):\n",
        "\n",
        "    trust_sum = np.sum(Trust_matrix.values, axis=0) - 1\n",
        "    similarity_sum = np.sum(Similarity_matrix.values, axis=0) - 1\n",
        "    ts_sumation = trust_sum + similarity_sum\n",
        "\n",
        "    LeaderId = np.argmax(ts_sumation)\n",
        "    LeaderImpact = ts_sumation[LeaderId] / (total_members - 1)\n",
        "    print(LeaderId)\n",
        "    return Trust_matrix.index[LeaderId], LeaderImpact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDN6yYZphpqd"
      },
      "outputs": [],
      "source": [
        "# Function to calculate influence weight based on leader's impact, similarity, and trust\n",
        "def calculate_influence_weight(leader_id, leader_impact, similarity_uv, trust_uv, v):\n",
        "\n",
        "    if v == leader_id:\n",
        "        weight_uv = (1/2) * ((leader_impact + (similarity_uv * trust_uv)) / (similarity_uv + trust_uv))\n",
        "    else:\n",
        "        weight_uv = (similarity_uv * trust_uv) / (similarity_uv + trust_uv)\n",
        "\n",
        "    return weight_uv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk3x6Jx4hpt1"
      },
      "outputs": [],
      "source": [
        "def influenced_rating(group):\n",
        "\n",
        "    members = group.index\n",
        "    movies = group.columns\n",
        "    num_members, num_items = len(members), len(movies)\n",
        "\n",
        "    # Calculate trust and similarity matrices\n",
        "    trust_matrix = calculate_trust(group)\n",
        "    similarity_matrix = calculate_similarity(group)\n",
        "\n",
        "    # Identify the leader and their impact\n",
        "    leader_id, leader_impact = identify_leader(trust_matrix, similarity_matrix, num_members)\n",
        "\n",
        "    influenced_ratings = pd.DataFrame(0.0, index=members, columns=movies)\n",
        "\n",
        "    for u in members:\n",
        "        for i in movies:\n",
        "            score_ui = group.at[u, i]\n",
        "            influence = 0\n",
        "\n",
        "            if score_ui > 0:\n",
        "                for v in members:\n",
        "                    if v != u:\n",
        "                        score_vi = group.at[v, i]\n",
        "                        similarity_uv = similarity_matrix.at[u, v]\n",
        "                        trust_uv = trust_matrix.at[u, v]\n",
        "                        weight_vu = calculate_influence_weight(leader_id, leader_impact, similarity_uv, trust_uv, v)\n",
        "\n",
        "                        if score_vi > 0:\n",
        "                            influence += weight_vu * (score_vi - score_ui)\n",
        "\n",
        "                influenced_ratings.at[u, i] = score_ui + influence\n",
        "\n",
        "    return influenced_ratings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQyt85ezhpvf"
      },
      "outputs": [],
      "source": [
        "def evaluate_recommendations(Group, Group_Rating, rec_size, satisfied_Tr):\n",
        "\n",
        "    Group_Rating = Group_Rating.sort_values(ascending=False)\n",
        "    rec_list = Group_Rating[Group_Rating != 0]\n",
        "\n",
        "    recommendation_index = rec_list.index\n",
        "    members = Group.index\n",
        "    no_member = len(members)\n",
        "\n",
        "    TP = TN = FP = FN = 0\n",
        "    satisfied = 1\n",
        "\n",
        "    for r, index in enumerate(recommendation_index):\n",
        "        for u in members:\n",
        "            preference_u_ind = Group.at[u, index]\n",
        "\n",
        "            if r < rec_size:\n",
        "                if preference_u_ind >= satisfied_Tr:\n",
        "                    satisfied += 1\n",
        "                    TP += 1\n",
        "                else:\n",
        "                    FP += 1\n",
        "            else:\n",
        "                if preference_u_ind >= satisfied_Tr:\n",
        "                    FN += 1\n",
        "                else:\n",
        "                    TN += 1\n",
        "\n",
        "    total_count = TP + FP + TN + FN\n",
        "\n",
        "    accuracy = ((TP + TN) / total_count) * 100 if total_count > 0 else 0\n",
        "    precision = (TP / (TP + FP)) * 100 if TP + FP > 0 else 0\n",
        "    recall = (TP / (TP + FN)) * 100 if TP + FN > 0 else 0\n",
        "    specificity = (TN / (TN + FP)) * 100 if TN + FP > 0 else 0\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "    balanced_accuracy = (specificity + recall) / 2\n",
        "\n",
        "    results = {\n",
        "        \"Satisfaction\": satisfied / (no_member * rec_size),\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"Specificity\": specificity,\n",
        "        \"Balanced_Accuracy\": balanced_accuracy,\n",
        "        \"F1_Score\": f1_score,\n",
        "        \"Confusion_counters\": {\"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN}\n",
        "    }\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c_zF9Cdhpzp",
        "outputId": "37633fdd-8d90-4135-d25a-b398effc9900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "Leader ID: gomezaddams\n",
            "Evaluation Results: {'Satisfaction': 0.2, 'Accuracy': 50.0, 'Precision': 0.0, 'Recall': 0, 'Specificity': 50.0, 'Balanced_Accuracy': 25.0, 'F1_Score': 0, 'Confusion_counters': {'TP': 0, 'FP': 5, 'TN': 5, 'FN': 0}}\n"
          ]
        }
      ],
      "source": [
        "# Main function to execute the recommendation system\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to execute the group recommendation system.\n",
        "\n",
        "    Reads group ratings from a CSV file, calculates influenced ratings, evaluates recommendations,\n",
        "    and prints the evaluation results.\n",
        "    \"\"\"\n",
        "    Group = pd.read_csv('/content/grouped data.csv')\n",
        "\n",
        "    users_id = Group[\"Unnamed: 0\"].unique()\n",
        "    Group = Group.drop(['Unnamed: 0'], axis=1)\n",
        "    Group = Group.set_axis(users_id, axis='rows')\n",
        "\n",
        "    # Calculate members' influenced ratings\n",
        "    Influenced_Ratings = influenced_rating(Group)\n",
        "\n",
        "    # Determine group rating for items using averaging aggregation method\n",
        "    Group_Rating = Influenced_Ratings.mean(axis=0).fillna(0)\n",
        "\n",
        "    # Identify the leader and their impact\n",
        "    trust_matrix = calculate_trust(Group)\n",
        "    similarity_matrix = calculate_similarity(Group)\n",
        "    total_members = len(Group)\n",
        "    leader_id, leader_impact = identify_leader(trust_matrix, similarity_matrix, total_members)\n",
        "\n",
        "    # Evaluate the recommendations\n",
        "    rec_size = 1\n",
        "    satisfied_Tr = 3\n",
        "    Evaluation_Results = evaluate_recommendations(Group, Group_Rating, rec_size, satisfied_Tr)\n",
        "\n",
        "    print(\"Leader ID:\", leader_id)\n",
        "    print(\"Evaluation Results:\", Evaluation_Results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIKye_HPhp1c",
        "outputId": "d35aa2dd-e0f5-443e-ad20-cd9851c367e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement skifuzzy (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for skifuzzy\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install skifuzzy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7is3xkm5hp4t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSid559yhp6d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCFVKEVYhp-h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLCrSnl8hqBK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKqOotuAhqD1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAvhf_VOhqFJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VyKmt3jhqI3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5GcVofmhqKi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vskcUoGhqOo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3myRczcYhqQU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnAXqYxHhqUP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0wukZrghqV8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rJ7Qq-EhqZs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBGpNdJthqbY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1aYhZGahqfA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmf61IxWhqgq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV0KIyxjhqi3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBlUYG80hqk_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ufF46pIhqok"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84Q78uNXhqqZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PybSYMefhqub"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTSvN9SThq0Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}